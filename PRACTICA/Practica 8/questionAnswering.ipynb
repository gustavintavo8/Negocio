{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Elegir una tarea (diferente de “text classification”). En el siguiente enlace, en la \n",
    "sección de “Natural Language Processing” se pueden inspeccionar diferentes tareas\n",
    "de minería de texto:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elegimos question answering y lo probamos con 2 modelos diferentes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: ¿Dónde está ubicado el Amazonas?\n",
      "Respuesta: el río más largo del mundo, ubicado en América del Sur\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Cargar el pipeline de QA con el modelo especificado\n",
    "qa_pipeline = pipeline(\"question-answering\", model=\"bert-large-uncased-whole-word-masking-finetuned-squad\")\n",
    "\n",
    "# Contexto y pregunta\n",
    "contexto = \"\"\"\n",
    "El Amazonas es el río más largo del mundo, ubicado en América del Sur. Su longitud supera los 7,000 kilómetros.\n",
    "\"\"\"\n",
    "pregunta = \"¿Dónde está ubicado el Amazonas?\"\n",
    "\n",
    "# Realizar la pregunta\n",
    "respuesta = qa_pipeline(question=pregunta, context=contexto)\n",
    "\n",
    "# Mostrar la respuesta\n",
    "print(f\"Pregunta: {pregunta}\")\n",
    "print(f\"Respuesta: {respuesta['answer']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pregunta: ¿Dónde está ubicado el Amazonas?\n",
      "Respuesta: América del Sur\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "# Cargar pipeline con otro modelo en español\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"PlanTL-GOB-ES/roberta-base-bne-sqac\",\n",
    "    tokenizer=\"PlanTL-GOB-ES/roberta-base-bne-sqac\",\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "contexto = \"El Amazonas es el río más largo del mundo, ubicado en América del Sur.\"\n",
    "pregunta = \"¿Dónde está ubicado el Amazonas?\"\n",
    "\n",
    "respuesta = qa_pipeline(question=pregunta, context=contexto)\n",
    "print(f\"Pregunta: {pregunta}\")\n",
    "print(f\"Respuesta: {respuesta['answer']}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Evaluar sobre el dataset elegido y hacer una comparativa de los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers datasets evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased-whole-word-masking-finetuned-squad were not used when initializing BertForQuestionAnswering: ['bert.pooler.dense.bias', 'bert.pooler.dense.weight']\n",
      "- This IS expected if you are initializing BertForQuestionAnswering from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForQuestionAnswering from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              Modelo    F1 Score  BLEU Score\n",
      "0                PlanTL-GOB-ES/roberta-base-bne-sqac  100.000000         0.0\n",
      "1  bert-large-uncased-whole-word-masking-finetune...   42.857143         0.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from evaluate import load\n",
    "from datasets import Dataset\n",
    "from transformers import pipeline\n",
    "\n",
    "# Cargar las métricas\n",
    "metric_squad = load(\"squad_v2\")  # Usar \"squad\" si no se espera respuesta nula\n",
    "metric_bleu = load(\"bleu\")  # Métrica BLEU\n",
    "\n",
    "# Datos de ejemplo\n",
    "data = Dataset.from_dict({\n",
    "    \"context\": [\n",
    "        \"El Amazonas es el río más largo del mundo, ubicado en América del Sur.\"\n",
    "    ],\n",
    "    \"question\": [\n",
    "        \"¿Dónde está ubicado el Amazonas?\"\n",
    "    ],\n",
    "    \"answers\": [\n",
    "        {\"text\": [\"América del Sur\"], \"answer_start\": [54]}\n",
    "    ]\n",
    "})\n",
    "\n",
    "# Definir modelos a comparar\n",
    "models = {\n",
    "    \"PlanTL-GOB-ES/roberta-base-bne-sqac\": pipeline(\"question-answering\", model=\"PlanTL-GOB-ES/roberta-base-bne-sqac\"),\n",
    "    \"bert-large-uncased-whole-word-masking-finetuned-squad\": pipeline(\"question-answering\", model=\"bert-large-uncased-whole-word-masking-finetuned-squad\"),\n",
    "}\n",
    "\n",
    "# Crear lista para almacenar métricas de cada modelo\n",
    "metrics_data = []\n",
    "\n",
    "# Evaluación de los modelos\n",
    "for model_name, qa_pipeline in models.items():\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for example in data:\n",
    "        # Realizar la predicción\n",
    "        prediction = qa_pipeline(\n",
    "            question=example[\"question\"],\n",
    "            context=example[\"context\"]\n",
    "        )[\"answer\"]\n",
    "\n",
    "        # Agregar predicciones y referencias en el formato esperado\n",
    "        predictions.append({\n",
    "            \"id\": str(example[\"question\"][0]),  # Usando la pregunta como ID\n",
    "            \"prediction_text\": prediction,\n",
    "            \"no_answer_probability\": 0.0  # Ajustar si es una pregunta sin respuesta\n",
    "        })\n",
    "        references.append({\n",
    "            \"id\": str(example[\"question\"][0]),\n",
    "            \"answers\": [{\"text\": example[\"answers\"][\"text\"][0], \"answer_start\": example[\"answers\"][\"answer_start\"][0]}]\n",
    "        })\n",
    "\n",
    "    # Calcular las métricas SQUAD (F1 Score)\n",
    "    squad_results = metric_squad.compute(predictions=predictions, references=references)\n",
    "    f1_score = squad_results[\"f1\"]\n",
    "\n",
    "    # Calcular BLEU score\n",
    "    bleu_results = metric_bleu.compute(predictions=[pred[\"prediction_text\"] for pred in predictions], references=[[ref[\"answers\"][0][\"text\"]] for ref in references])\n",
    "    bleu_score = bleu_results[\"bleu\"]\n",
    "\n",
    "    # Almacenar las métricas en la lista\n",
    "    metrics_data.append({\n",
    "        \"Modelo\": model_name,\n",
    "        \"F1 Score\": f1_score,\n",
    "        \"BLEU Score\": bleu_score\n",
    "    })\n",
    "\n",
    "# Crear un DataFrame de pandas para mostrar la tabla\n",
    "df_metrics = pd.DataFrame(metrics_data)\n",
    "\n",
    "# Mostrar la tabla de métricas\n",
    "print(df_metrics)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting gradio\n",
      "  Downloading gradio-5.8.0-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
      "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: anyio<5.0,>=3.0 in c:\\program files\\python312\\lib\\site-packages (from gradio) (4.4.0)\n",
      "Collecting fastapi<1.0,>=0.115.2 (from gradio)\n",
      "  Downloading fastapi-0.115.6-py3-none-any.whl.metadata (27 kB)\n",
      "Collecting ffmpy (from gradio)\n",
      "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting gradio-client==1.5.1 (from gradio)\n",
      "  Downloading gradio_client-1.5.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: httpx>=0.24.1 in c:\\program files\\python312\\lib\\site-packages (from gradio) (0.27.0)\n",
      "Collecting huggingface-hub>=0.25.1 (from gradio)\n",
      "  Downloading huggingface_hub-0.26.5-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: jinja2<4.0 in c:\\program files\\python312\\lib\\site-packages (from gradio) (3.1.4)\n",
      "Requirement already satisfied: markupsafe~=2.0 in c:\\program files\\python312\\lib\\site-packages (from gradio) (2.1.5)\n",
      "Requirement already satisfied: numpy<3.0,>=1.0 in c:\\program files\\python312\\lib\\site-packages (from gradio) (1.26.4)\n",
      "Collecting orjson~=3.0 (from gradio)\n",
      "  Downloading orjson-3.10.12-cp312-none-win_amd64.whl.metadata (42 kB)\n",
      "Requirement already satisfied: packaging in c:\\program files\\python312\\lib\\site-packages (from gradio) (24.1)\n",
      "Requirement already satisfied: pandas<3.0,>=1.0 in c:\\program files\\python312\\lib\\site-packages (from gradio) (2.2.2)\n",
      "Requirement already satisfied: pillow<12.0,>=8.0 in c:\\program files\\python312\\lib\\site-packages (from gradio) (10.3.0)\n",
      "Collecting pydantic>=2.0 (from gradio)\n",
      "  Downloading pydantic-2.10.3-py3-none-any.whl.metadata (172 kB)\n",
      "Collecting pydub (from gradio)\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Collecting python-multipart>=0.0.18 (from gradio)\n",
      "  Downloading python_multipart-0.0.19-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: pyyaml<7.0,>=5.0 in c:\\program files\\python312\\lib\\site-packages (from gradio) (6.0.1)\n",
      "Collecting ruff>=0.2.2 (from gradio)\n",
      "  Downloading ruff-0.8.3-py3-none-win_amd64.whl.metadata (25 kB)\n",
      "Collecting safehttpx<0.2.0,>=0.1.6 (from gradio)\n",
      "  Downloading safehttpx-0.1.6-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting semantic-version~=2.0 (from gradio)\n",
      "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting starlette<1.0,>=0.40.0 (from gradio)\n",
      "  Using cached starlette-0.41.3-py3-none-any.whl.metadata (6.0 kB)\n",
      "Collecting tomlkit<0.14.0,>=0.12.0 (from gradio)\n",
      "  Downloading tomlkit-0.13.2-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting typer<1.0,>=0.12 (from gradio)\n",
      "  Downloading typer-0.15.1-py3-none-any.whl.metadata (15 kB)\n",
      "Requirement already satisfied: typing-extensions~=4.0 in c:\\program files\\python312\\lib\\site-packages (from gradio) (4.12.2)\n",
      "Requirement already satisfied: uvicorn>=0.14.0 in c:\\users\\uo286277\\appdata\\roaming\\python\\python312\\site-packages (from gradio) (0.32.1)\n",
      "Requirement already satisfied: fsspec in c:\\users\\uo286277\\appdata\\roaming\\python\\python312\\site-packages (from gradio-client==1.5.1->gradio) (2023.12.2)\n",
      "Requirement already satisfied: websockets<15.0,>=10.0 in c:\\users\\uo286277\\appdata\\roaming\\python\\python312\\site-packages (from gradio-client==1.5.1->gradio) (11.0.3)\n",
      "Requirement already satisfied: idna>=2.8 in c:\\program files\\python312\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
      "Requirement already satisfied: sniffio>=1.1 in c:\\program files\\python312\\lib\\site-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
      "Requirement already satisfied: certifi in c:\\program files\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (2024.6.2)\n",
      "Requirement already satisfied: httpcore==1.* in c:\\program files\\python312\\lib\\site-packages (from httpx>=0.24.1->gradio) (1.0.5)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in c:\\program files\\python312\\lib\\site-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
      "Requirement already satisfied: filelock in c:\\program files\\python312\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (3.15.4)\n",
      "Requirement already satisfied: requests in c:\\program files\\python312\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\program files\\python312\\lib\\site-packages (from huggingface-hub>=0.25.1->gradio) (4.66.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\program files\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\program files\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\program files\\python312\\lib\\site-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\uo286277\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.1 in c:\\users\\uo286277\\appdata\\roaming\\python\\python312\\site-packages (from pydantic>=2.0->gradio) (2.27.1)\n",
      "Requirement already satisfied: click>=8.0.0 in c:\\users\\uo286277\\appdata\\roaming\\python\\python312\\site-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.12->gradio)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in c:\\program files\\python312\\lib\\site-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
      "Requirement already satisfied: colorama in c:\\program files\\python312\\lib\\site-packages (from click>=8.0.0->typer<1.0,>=0.12->gradio) (0.4.6)\n",
      "Requirement already satisfied: six>=1.5 in c:\\program files\\python312\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3.0,>=1.0->gradio) (1.16.0)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\program files\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\program files\\python312\\lib\\site-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.18.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\program files\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\program files\\python312\\lib\\site-packages (from requests->huggingface-hub>=0.25.1->gradio) (2.2.2)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\program files\\python312\\lib\\site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
      "Downloading gradio-5.8.0-py3-none-any.whl (57.2 MB)\n",
      "   ---------------------------------------- 0.0/57.2 MB ? eta -:--:--\n",
      "   - -------------------------------------- 2.4/57.2 MB 12.2 MB/s eta 0:00:05\n",
      "   --- ------------------------------------ 4.7/57.2 MB 11.9 MB/s eta 0:00:05\n",
      "   ---- ----------------------------------- 6.8/57.2 MB 11.3 MB/s eta 0:00:05\n",
      "   ------ --------------------------------- 9.2/57.2 MB 11.4 MB/s eta 0:00:05\n",
      "   -------- ------------------------------- 11.5/57.2 MB 11.5 MB/s eta 0:00:04\n",
      "   --------- ------------------------------ 14.2/57.2 MB 11.5 MB/s eta 0:00:04\n",
      "   ----------- ---------------------------- 15.7/57.2 MB 11.6 MB/s eta 0:00:04\n",
      "   ------------- -------------------------- 18.9/57.2 MB 11.7 MB/s eta 0:00:04\n",
      "   -------------- ------------------------- 21.2/57.2 MB 11.7 MB/s eta 0:00:04\n",
      "   ---------------- ----------------------- 23.6/57.2 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------ --------------------- 26.2/57.2 MB 11.7 MB/s eta 0:00:03\n",
      "   ------------------- -------------------- 28.6/57.2 MB 11.7 MB/s eta 0:00:03\n",
      "   --------------------- ------------------ 31.2/57.2 MB 11.7 MB/s eta 0:00:03\n",
      "   ----------------------- ---------------- 33.8/57.2 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------- -------------- 36.2/57.2 MB 11.7 MB/s eta 0:00:02\n",
      "   -------------------------- ------------- 38.5/57.2 MB 11.7 MB/s eta 0:00:02\n",
      "   ---------------------------- ----------- 40.9/57.2 MB 11.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 43.3/57.2 MB 11.7 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 45.9/57.2 MB 11.7 MB/s eta 0:00:01\n",
      "   --------------------------------- ------ 48.2/57.2 MB 11.7 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 50.6/57.2 MB 11.8 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 53.2/57.2 MB 11.7 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 55.6/57.2 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------  57.1/57.2 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 57.2/57.2 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading gradio_client-1.5.1-py3-none-any.whl (320 kB)\n",
      "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
      "Downloading fastapi-0.115.6-py3-none-any.whl (94 kB)\n",
      "Downloading huggingface_hub-0.26.5-py3-none-any.whl (447 kB)\n",
      "Downloading orjson-3.10.12-cp312-none-win_amd64.whl (135 kB)\n",
      "Downloading pydantic-2.10.3-py3-none-any.whl (456 kB)\n",
      "Downloading python_multipart-0.0.19-py3-none-any.whl (24 kB)\n",
      "Downloading ruff-0.8.3-py3-none-win_amd64.whl (9.6 MB)\n",
      "   ---------------------------------------- 0.0/9.6 MB ? eta -:--:--\n",
      "   --------- ------------------------------ 2.4/9.6 MB 12.2 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 4.7/9.6 MB 11.9 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 7.1/9.6 MB 11.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------  9.4/9.6 MB 11.7 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 9.6/9.6 MB 11.3 MB/s eta 0:00:00\n",
      "Downloading safehttpx-0.1.6-py3-none-any.whl (8.7 kB)\n",
      "Downloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
      "Downloading starlette-0.41.3-py3-none-any.whl (73 kB)\n",
      "Downloading tomlkit-0.13.2-py3-none-any.whl (37 kB)\n",
      "Downloading typer-0.15.1-py3-none-any.whl (44 kB)\n",
      "Downloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Installing collected packages: pydub, tomlkit, shellingham, semantic-version, ruff, python-multipart, orjson, ffmpy, aiofiles, starlette, pydantic, huggingface-hub, typer, safehttpx, gradio-client, fastapi, gradio\n",
      "  Attempting uninstall: python-multipart\n",
      "    Found existing installation: python-multipart 0.0.17\n",
      "    Uninstalling python-multipart-0.0.17:\n",
      "      Successfully uninstalled python-multipart-0.0.17\n",
      "  Attempting uninstall: starlette\n",
      "    Found existing installation: starlette 0.22.0\n",
      "    Uninstalling starlette-0.22.0:\n",
      "      Successfully uninstalled starlette-0.22.0\n",
      "  Attempting uninstall: pydantic\n",
      "    Found existing installation: pydantic 1.10.19\n",
      "    Uninstalling pydantic-1.10.19:\n",
      "      Successfully uninstalled pydantic-1.10.19\n",
      "  Attempting uninstall: fastapi\n",
      "    Found existing installation: fastapi 0.88.0\n",
      "    Uninstalling fastapi-0.88.0:\n",
      "      Successfully uninstalled fastapi-0.88.0\n",
      "Successfully installed aiofiles-23.2.1 fastapi-0.115.6 ffmpy-0.4.0 gradio-5.8.0 gradio-client-1.5.1 huggingface-hub-0.26.5 orjson-3.10.12 pydantic-2.10.3 pydub-0.25.1 python-multipart-0.0.19 ruff-0.8.3 safehttpx-0.1.6 semantic-version-2.10.0 shellingham-1.5.4 starlette-0.41.3 tomlkit-0.13.2 typer-0.15.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "lightning 2.0.0 requires fastapi<0.89.0, but you have fastapi 0.115.6 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr\n",
    "from transformers import pipeline\n",
    "\n",
    "# Cargar el pipeline de QA con el modelo elegido\n",
    "qa_pipeline = pipeline(\n",
    "    \"question-answering\",\n",
    "    model=\"PlanTL-GOB-ES/roberta-base-bne-sqac\",\n",
    "    tokenizer=\"PlanTL-GOB-ES/roberta-base-bne-sqac\",\n",
    "    framework=\"pt\"\n",
    ")\n",
    "\n",
    "# Función para realizar la predicción\n",
    "def responder_pregunta(contexto, pregunta):\n",
    "    respuesta = qa_pipeline(question=pregunta, context=contexto)\n",
    "    return respuesta['answer']\n",
    "\n",
    "# Crear la interfaz de Gradio\n",
    "interface = gr.Interface(\n",
    "    fn=responder_pregunta, \n",
    "    inputs=[\n",
    "        gr.Textbox(label=\"Contexto\", placeholder=\"Introduce el contexto aquí...\", lines=5),\n",
    "        gr.Textbox(label=\"Pregunta\", placeholder=\"Introduce la pregunta aquí...\")\n",
    "    ], \n",
    "    outputs=gr.Textbox(label=\"Respuesta\"),\n",
    "    live=True\n",
    ")\n",
    "\n",
    "# Iniciar la interfaz\n",
    "interface.launch(share=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
